{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d2d7d0",
   "metadata": {},
   "source": [
    "# RSSI Localization Pipeline\n",
    "This notebook documents the full neural-network + local KNN pipeline used to locate the WiFi probe on the board. Each cell explains how a raw RSSI vector is transformed into an embedding, how the L-KNN votes, and which diagnostics you can read to understand the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa5421",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Run `PYTHONPATH=src python -m localization.pipeline ...` at least once to produce `reports/localizer.joblib` and the generated metrics (confusion matrix, JSON report, etc.).\n",
    "- Work inside the same Python environment (`.venv`) so that the imported modules and dependencies match those used during training.\n",
    "- Keep the measurement folders `ddeuxmetres/` and `dquatremetres/` available since this notebook loads them directly.\n",
    "- Glossary of terms used below:\n",
    "  - **RSSI (Received Signal Strength Indicator)**: WiFi power in dBm reported by the router for each antenna.\n",
    "  - **Embedding**: compact vector representation produced by the MLP to summarize the RSSI pattern of a cell.\n",
    "  - **Local KNN (L-KNN)**: distance-weighted K-nearest neighbors operating in the embedding space to predict the cell ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb53cf4",
   "metadata": {},
   "source": [
    "## Phase 1 - Prepare the tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules: filesystem helpers, plotting, math utilities, and our local code.\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Image\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.style.use('seaborn-v0_8')  # readable styling for plots\n",
    "\n",
    "# Define important paths: project root, measurement folders, trained model, and the cell layout image.\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "DATA_FOLDERS = [PROJECT_ROOT / 'ddeuxmetres', PROJECT_ROOT / 'dquatremetres']\n",
    "MODEL_PATH = PROJECT_ROOT / 'reports' / 'localizer.joblib'\n",
    "GRID_IMAGE_PATH = PROJECT_ROOT / 'lesgridcells.png'\n",
    "\n",
    "# Allow imports from the local `src/` directory.\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "from localization.data import CampaignSpec, load_measurements, DEFAULT_CELL_WIDTH_M, DEFAULT_CELL_HEIGHT_M\n",
    "from localization.embedding_knn import EmbeddingKnnLocalizer, _apply_activation\n",
    "\n",
    "FEATURE_COLUMNS = [\"Signal\", \"Noise\", \"signal_A1\", \"signal_A2\", \"signal_A3\", \"router_distance_m\"]\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Expected model path: {MODEL_PATH}\")\n",
    "\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd6bb4",
   "metadata": {},
   "source": [
    "We configure project paths, add `src/` to `sys.path`, and import the helper modules (`localization.data`, `localization.embedding_knn`). This also defines the RSSI feature list (`FEATURE_COLUMNS`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c39d4",
   "metadata": {},
   "source": [
    "## Phase 2 - Load and combine measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the list of campaigns (2 m + 4 m) that are actually present on disk.\n",
    "campaigns = [CampaignSpec(path) for path in DATA_FOLDERS if path.exists()]\n",
    "if not campaigns:\n",
    "    raise RuntimeError(\"No campaign found. Verify that `ddeuxmetres/` and `dquatremetres/` exist.\")\n",
    "\n",
    "# Merge every CSV into a single DataFrame while keeping grid/campaign metadata.\n",
    "df = load_measurements(campaigns)\n",
    "print(f\"Loaded {len(df)} rows covering {df['grid_cell'].nunique()} cells.\")\n",
    "display(df.head())\n",
    "\n",
    "# Quick lookup table to retrieve spatial info (grid indices, metric coordinates, campaign name).\n",
    "cell_lookup = (\n",
    "    df[[\"grid_cell\", \"grid_x\", \"grid_y\", \"coord_x_m\", \"coord_y_m\", \"campaign\"]]\n",
    "    .drop_duplicates(\"grid_cell\")\n",
    "    .set_index(\"grid_cell\")\n",
    ")\n",
    "GRID_WIDTH_M = df[\"coord_x_m\"].max() + DEFAULT_CELL_WIDTH_M / 2\n",
    "GRID_HEIGHT_M = df[\"coord_y_m\"].max() + DEFAULT_CELL_HEIGHT_M / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a392d5",
   "metadata": {},
   "source": [
    "The campaigns `ddeuxmetres` and `dquatremetres` are merged into a single DataFrame. Each row contains:\n",
    "- the RSSI values (`Signal`, `Noise`, `signal_Ai`),\n",
    "- the discrete grid indices (`grid_x`, `grid_y`) and the corresponding metric coordinates,\n",
    "- the campaign label (router distance).\n",
    "By centralizing everything, we can train/evaluate without any extra preprocessing outside Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9a4e9",
   "metadata": {},
   "source": [
    "### Looking at a raw CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first CSV available to illustrate the raw data structure generated by collect_wifi.sh.\n",
    "example_csv = None\n",
    "for folder in DATA_FOLDERS:\n",
    "    if not folder.exists():\n",
    "        continue\n",
    "    candidates = sorted(folder.glob('*.csv'))\n",
    "    if candidates:\n",
    "        example_csv = candidates[0]\n",
    "        break\n",
    "if example_csv is None:\n",
    "    raise FileNotFoundError(\"No CSV found in the campaign folders.\")\n",
    "\n",
    "print(f\"Example raw file: {example_csv.relative_to(PROJECT_ROOT)}\")\n",
    "raw_example = pd.read_csv(example_csv)\n",
    "display(raw_example.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc7df1",
   "metadata": {},
   "source": [
    "This preview of a raw CSV shows why `load_measurements` enriches the data: the files record only RSSI values. Grid metadata and router distance are injected in Python to make the dataset self-contained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86276034",
   "metadata": {},
   "source": [
    "## Phase 3 - Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a616b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model (MLP encoder + L-KNN).\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(\"Trained model missing. Rerun localization.pipeline to generate reports/localizer.joblib.\")\n",
    "\n",
    "localizer: EmbeddingKnnLocalizer = joblib.load(MODEL_PATH)\n",
    "print(\"MLP architecture:\", localizer.encoder_.hidden_layer_sizes)\n",
    "print(\"KNN parameters:\", localizer.knn_.get_params())\n",
    "print(f\"Iterations performed: {localizer.encoder_.n_iter_}\")\n",
    "print(f\"Final loss value: {localizer.encoder_.loss_curve_[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa00662",
   "metadata": {},
   "source": [
    "The trained model ships two components:\n",
    "1. a supervised MLP encoder (32-dimension embedding) implemented with `scikit-learn`,\n",
    "2. a distance-weighted KNN operating on those embeddings.\n",
    "`localizer.encoder_` and `localizer.knn_` are therefore available for inspection throughout this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ba072",
   "metadata": {},
   "source": [
    "### Inspect training loss convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc135d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(localizer.encoder_.loss_curve_, marker='o')  # loss recorded by scikit-learn\n",
    "plt.title(\"MLP training loss\")\n",
    "plt.xlabel(\"Adam iterations\")\n",
    "plt.ylabel(\"Loss (cross-entropy)\")\n",
    "plt.grid(True, alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6f55d",
   "metadata": {},
   "source": [
    "When the loss curve flattens the encoder has converged with the provided hyper-parameters. Otherwise you would adjust `learning_rate_init`, `alpha`, or `max_iter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfb227",
   "metadata": {},
   "source": [
    "## Phase 4 - Select a sample to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436053c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid cell (and optionally the campaign) we want to inspect.\n",
    "TARGET_CELL = '1_4'      # change this to inspect another location\n",
    "CAMPAIGN_NAME = None      # set to 'ddeuxmetres' or 'dquatremetres' to filter a campaign\n",
    "\n",
    "subset = df[df['grid_cell'] == TARGET_CELL]\n",
    "if CAMPAIGN_NAME:\n",
    "    subset = subset[subset['campaign'] == CAMPAIGN_NAME]\n",
    "if subset.empty:\n",
    "    raise ValueError(f\"No sample found for {TARGET_CELL} (campaign={CAMPAIGN_NAME}).\")\n",
    "\n",
    "# Random but reproducible pick thanks to random_state.\n",
    "sample = subset.sample(1, random_state=7)\n",
    "sample_features = sample[FEATURE_COLUMNS]\n",
    "sample_meta = sample[['grid_cell', 'grid_x', 'grid_y', 'coord_x_m', 'coord_y_m', 'campaign']]\n",
    "\n",
    "display(Markdown(\n",
    "    f\"### Selected sample: cell `{sample_meta.iloc[0]['grid_cell']}` (campaign `{sample_meta.iloc[0]['campaign']}`)\"\n",
    "))\n",
    "display(sample_features)\n",
    "display(sample_meta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a6e51",
   "metadata": {},
   "source": [
    "This cell selects the sample to analyze (`TARGET_CELL`) and produces two frames:\n",
    "- `sample_features`: the six RSSI features plus router distance passed to the model,\n",
    "- `sample_meta`: grid indices, physical coordinates and campaign metadata used for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39315952",
   "metadata": {},
   "source": [
    "### 4.1 - Standardization (centering / scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scaler stores the training-set mean and standard deviation for each feature.\n",
    "scaler = localizer.scaler_\n",
    "raw_vec = sample_features.to_numpy()\n",
    "scaled_vec = scaler.transform(raw_vec)\n",
    "\n",
    "scaling_table = pd.DataFrame(\n",
    "    {\n",
    "        'feature': FEATURE_COLUMNS,\n",
    "        'raw_value': raw_vec.flatten(),\n",
    "        'training_mean': scaler.mean_,\n",
    "        'training_std': scaler.scale_,\n",
    "        'standardized_value': scaled_vec.flatten(),\n",
    "    }\n",
    ")\n",
    "display(scaling_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d224563",
   "metadata": {},
   "source": [
    "`StandardScaler` enforces zero mean and unit variance for every feature. Without this normalization either `Signal` or `router_distance_m` would dominate the MLP gradients and the Euclidean distance used by L-KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6713f2",
   "metadata": {},
   "source": [
    "### 4.2 - Physical location of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29579c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coord_text = (\n",
    "    f\"Physical coordinates (m): x = {sample_meta.iloc[0]['coord_x_m']:.3f}, y = {sample_meta.iloc[0]['coord_y_m']:.3f}<br>\"\n",
    "    f\"Grid index: (grid_x={sample_meta.iloc[0]['grid_x']}, grid_y={sample_meta.iloc[0]['grid_y']})\"\n",
    ")\n",
    "display(Markdown(coord_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c98f11",
   "metadata": {},
   "source": [
    "Physical coordinates (meters) are also used when computing the Euclidean localization error `error_m = ||coord_true - coord_pred||`. The values correspond to the center of the instrumented cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f955513",
   "metadata": {},
   "source": [
    "### 4.3 - Propagate through the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pass through every MLP layer to inspect how the sample is transformed.\n",
    "activations = []\n",
    "activation = scaled_vec\n",
    "weight_count = len(localizer.encoder_.coefs_)\n",
    "for idx, (weights, bias) in enumerate(zip(localizer.encoder_.coefs_, localizer.encoder_.intercepts_)):\n",
    "    linear = activation @ weights + bias  # linear transformation of the current layer\n",
    "    is_output = idx == weight_count - 1\n",
    "    layer_name = 'output_logits' if is_output else f'hidden_{idx+1}'\n",
    "    if not is_output:\n",
    "        activation = _apply_activation(linear, localizer.encoder_.activation)\n",
    "    else:\n",
    "        activation = linear\n",
    "    activations.append(\n",
    "        {\n",
    "            'layer': layer_name,\n",
    "            'units': linear.shape[1],\n",
    "            'min': float(activation.min()),\n",
    "            'max': float(activation.max()),\n",
    "            'preview_first5': np.round(activation[0, :5], 4).tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "display(pd.DataFrame(activations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e6e7c",
   "metadata": {},
   "source": [
    "Each hidden layer applies a linear transformation followed by the activation (`ReLU`). The min/max columns make it easy to check that the activations are not saturated. The embedding consumed by L-KNN is simply the last hidden layer (32 values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding = localizer.transform(sample_features)\n",
    "print(f\"Taille de l'embedding : {embedding.shape}\")\n",
    "embedding_df = pd.DataFrame(embedding, columns=[f\"e{i}\" for i in range(embedding.shape[1])])\n",
    "display(embedding_df.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15b0f1",
   "metadata": {},
   "source": [
    "The 32-component vector (`e0..e31`) is the input to the L-KNN. Cells that are close in the physical grid should produce embeddings that are close in this space; otherwise the neighbor search would be unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72318c",
   "metadata": {},
   "source": [
    "## Phase 5 - L-KNN decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380980a",
   "metadata": {},
   "source": [
    "### 5.0 - Heatmap of average RSSI\n",
    "Before analyzing a specific sample we plot the mean `Signal` per cell to ensure the spatial gradient still reflects the router placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_signal = df.pivot_table(index='grid_x', columns='grid_y', values='Signal', aggfunc='mean')\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(mean_signal.sort_index(ascending=False), cmap='inferno', aspect='auto')\n",
    "plt.colorbar(label='Average RSSI (dBm)')\n",
    "plt.title('Heatmap of mean RSSI per cell')\n",
    "plt.xlabel('grid_y (columns)')\n",
    "plt.ylabel('grid_x (0 = top row)')\n",
    "plt.xticks(range(mean_signal.shape[1]), mean_signal.columns)\n",
    "plt.yticks(range(mean_signal.shape[0]), sorted(mean_signal.index, reverse=True))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f23f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the cell probabilities, final prediction, and the K nearest neighbors.\n",
    "y_proba = localizer.predict_proba(sample_features)\n",
    "y_pred = localizer.predict(sample_features)\n",
    "neighbor_dist, neighbor_cells = localizer.explain(sample_features, top_k=5)\n",
    "\n",
    "print(f\"Predicted cell: {y_pred[0]} | max confidence: {y_proba.max():.4f}\")\n",
    "\n",
    "neighbor_df = pd.DataFrame(\n",
    "    {\n",
    "        'rank': np.arange(1, neighbor_cells.shape[1] + 1),\n",
    "        'cell': neighbor_cells[0],\n",
    "        'distance_embedding': neighbor_dist[0],\n",
    "    }\n",
    ")\n",
    "neighbor_df = neighbor_df.join(cell_lookup, on='cell')\n",
    "display(neighbor_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a08b0e",
   "metadata": {},
   "source": [
    "`neighbor_df` lists the `K` reference cells sorted by Euclidean distance in the latent space. It doubles as an explainability artifact: you know exactly which historical fingerprints contributed to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835b08a",
   "metadata": {},
   "source": [
    "### 5.1 - Histogram of neighbor distances\n",
    "Each bar corresponds to one of the `K` neighbors returned by L-KNN. We label the x-axis with the neighbor rank so repeated cell names do not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(neighbor_df['rank'], neighbor_df['distance_embedding'], color='dodgerblue')\n",
    "plt.xticks(neighbor_df['rank'], neighbor_df['cell'], rotation=45, ha='right')\n",
    "plt.xlabel('Neighbor rank')\n",
    "plt.ylabel('Embedding distance')\n",
    "plt.title('Top-K neighbors: embedding distances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b49c2",
   "metadata": {},
   "source": [
    "### 5.2 - Neighbor vote contributions\n",
    "Distances are converted to weights (`1/distance`) to visualize how much each neighbor contributes to the L-KNN vote. The weights sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fa2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1 / (neighbor_df['distance_embedding'] + 1e-6)\n",
    "weights = weights / weights.sum()\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(neighbor_df['cell'], weights, color='mediumseagreen')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('normalized weight')\n",
    "plt.title('Neighbor contribution in the KNN vote')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f5922",
   "metadata": {},
   "source": [
    "### 5.3 - Project neighbors on the board picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if GRID_IMAGE_PATH.exists():\n",
    "    img = plt.imread(GRID_IMAGE_PATH)  # background picture of the magnetic board\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    def cell_to_pixels(cell_name: str):\n",
    "        \"\"\"Map a cell identifier to pixel coordinates on the image.\"\"\"\n",
    "        entry = cell_lookup.loc[cell_name]\n",
    "        x_norm = entry['coord_x_m'] / GRID_WIDTH_M\n",
    "        y_norm = entry['coord_y_m'] / GRID_HEIGHT_M\n",
    "        px = x_norm * img.shape[1]\n",
    "        py = y_norm * img.shape[0]\n",
    "        return px, py\n",
    "\n",
    "    # Actual vs predicted position of the inspected sample.\n",
    "    true_px, true_py = cell_to_pixels(sample_meta.iloc[0]['grid_cell'])\n",
    "    pred_px, pred_py = cell_to_pixels(y_pred[0])\n",
    "\n",
    "    ax.scatter([true_px], [true_py], c='lime', s=120, marker='o', edgecolors='black', label='Ground truth cell')\n",
    "    ax.scatter([pred_px], [pred_py], c='red', s=120, marker='x', label='Predicted cell')\n",
    "\n",
    "    # Visualize the K neighbors that influenced the vote.\n",
    "    for _, row in neighbor_df.iterrows():\n",
    "        px, py = cell_to_pixels(row['cell'])\n",
    "        ax.scatter(px, py, c='dodgerblue', s=80, alpha=0.7)\n",
    "        label_txt = f\"{row['cell']} (dist={row['distance_embedding']:.3f})\"\n",
    "        ax.text(\n",
    "            px + 10,\n",
    "            py,\n",
    "            label_txt,\n",
    "            color='white',\n",
    "            fontsize=8,\n",
    "            bbox=dict(facecolor='black', alpha=0.4, pad=2),\n",
    "        )\n",
    "\n",
    "    ax.set_title('Neighbors projected on the board (background = lesgridcells.png)')\n",
    "    ax.axis('off')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Image lesgridcells.png missing: overlay cannot be displayed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07292e",
   "metadata": {},
   "source": [
    "### 5.4 - Confusion matrix and reliability curve\n",
    "- The confusion matrix (saved by `localization.pipeline`) highlights cells that are systematically confused.\n",
    "- The reliability curve plots average model confidence vs observed accuracy to validate probability calibration.\n",
    "- The bar chart shows how confidence scores are distributed across all measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a181488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix generated by the training pipeline\n",
    "confusion_path = REPORTS_DIR / 'confusion_matrix.png'\n",
    "if confusion_path.exists():\n",
    "    display(Image(filename=confusion_path))\n",
    "else:\n",
    "    print(\"confusion_matrix.png missing: rerun localization.pipeline to regenerate it.\")\n",
    "\n",
    "# Reliability curve on the entire dataset\n",
    "all_probs = localizer.predict_proba(df[FEATURE_COLUMNS])\n",
    "all_preds = localizer.predict(df[FEATURE_COLUMNS])\n",
    "conf_max = all_probs.max(axis=1)\n",
    "correct = (all_preds == df['grid_cell'].to_numpy())\n",
    "bins = np.linspace(0, 1, 11)\n",
    "indices = np.digitize(conf_max, bins) - 1\n",
    "centers = []\n",
    "accuracies = []\n",
    "counts = []\n",
    "for i in range(len(bins) - 1):\n",
    "    mask = indices == i\n",
    "    if mask.any():\n",
    "        centers.append(conf_max[mask].mean())\n",
    "        accuracies.append(correct[mask].mean())\n",
    "        counts.append(mask.sum())\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray', label='Ideal calibration')\n",
    "plt.plot(centers, accuracies, 'o-', color='dodgerblue', label='Model')\n",
    "plt.xlabel('Average predicted confidence')\n",
    "plt.ylabel('Observed accuracy')\n",
    "plt.title('Reliability curve (all measurements)')\n",
    "plt.grid(True, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if centers:\n",
    "    plt.figure(figsize=(5, 2.5))\n",
    "    plt.bar(centers, counts, width=0.05, color='lightgray')\n",
    "    plt.xlabel('Average confidence')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.title('Confidence histogram')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot plot the confidence histogram: no confidence bins available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a294e59",
   "metadata": {},
   "source": [
    "This figure brings everything together: green = ground truth cell, red = predicted cell, blue markers = the neighbor cells consulted by the L-KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf2c91",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Modify `TARGET_CELL` / `CAMPAIGN_NAME` to validate other positions or router distances.\n",
    "- Add new measurement campaigns (different router heights, obstacles, etc.) and re-run the notebook to stress the embeddings.\n",
    "- Export `neighbor_df`, histogram and weight plots into QA reports or dashboards so stakeholders can review the decision path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
